corpus_path: /data00/yifei_chen/FlashRAG/examples/quick_start/indexes/general_knowledge.jsonl
data_dir: /data00/yifei_chen/multi_llms_for_CoT/datasets/nq/test.jsonl
dataset_name: nq
dataset_path: /data00/yifei_chen/multi_llms_for_CoT/datasets/nq/test.jsonl/nq
device: !!python/object/apply:torch.device
- cuda
faiss_gpu: false
framework: fschat
generation_params:
  do_sample: false
  max_tokens: 32
  temperature: 1.0
  top_p: 0.2
generator_batch_size: 4
generator_max_input_len: 1024
generator_model: llama3-8B-instruct
generator_model_path: llama3-8B-instruct
gpu_id: 0,1,2,3
gpu_memory_utilization: 0.85
index_path: /data00/yifei_chen/FlashRAG/examples/quick_start/indexes/e5_Flat.index
method2index:
  bm25: null
  contriever: null
  e5: null
metric_setting:
  retrieval_recall_topk: 5
  tokenizer_name: gpt-4
metrics:
- em
- f1
- acc
- precision
- recall
- input_tokens
model2path:
  bge: intfloat/e5-base-v2
  contriever: facebook/contriever
  e5: intfloat/e5-base-v2
  llama2-13B: meta-llama/Llama-2-13b-hf
  llama2-13B-chat: meta-llama/Llama-2-13b-chat-hf
  llama2-7B: meta-llama/Llama-2-7b-hf
  llama2-7B-chat: meta-llama/Llama-2-7b-chat-hf
model2pooling:
  bge: cls
  contriever: mean
  dpr: cls
  e5: mean
  jina: mean
openai_setting:
  api_key: null
  base_url: null
random_sample: false
rerank_batch_size: 256
rerank_max_length: 512
rerank_model_name: null
rerank_model_path: null
rerank_pooling_method: null
rerank_topk: 5
rerank_use_fp16: true
retrieval_batch_size: 5
retrieval_cache_path: null
retrieval_method: e5
retrieval_model_path: intfloat/e5-base-v2
retrieval_pooling_method: mean
retrieval_query_max_length: 128
retrieval_topk: 5
retrieval_use_fp16: true
save_dir: output/nq_2024_09_23_16_25_experiment
save_intermediate_data: true
save_metric_score: true
save_note: experiment
save_retrieval_cache: false
seed: 2024
split:
- test
test_sample_num: null
use_fid: false
use_reranker: false
use_retrieval_cache: false
use_sentence_transformer: false
